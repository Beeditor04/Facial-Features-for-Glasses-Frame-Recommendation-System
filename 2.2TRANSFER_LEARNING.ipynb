{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import dlib\n",
                "import os\n",
                "from sklearn.cluster import KMeans\n",
                "from matplotlib import pyplot as plt\n",
                "from skimage.feature import hog\n",
                "from skimage import exposure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "dir_train = r'.\\cropped_dataset\\train'\n",
                "dir_test = r'.\\cropped_dataset\\test'\n",
                "dir_model = r'.\\model'\n",
                "\n",
                "\n",
                "detector = dlib.get_frontal_face_detector()\n",
                "predictor = dlib.shape_predictor(dir_model + \"\\\\\" + \"shape_predictor_68_face_landmarks.dat\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def edge_segmentation(image):\n",
                "    edges = cv2.Canny(image, 100, 200)\n",
                "    return edges\n",
                "\n",
                "# Feature extraction (dummy example)\n",
                "\n",
                "def extract_features(image):\n",
                "    # Resize the image to 128x128\n",
                "    image_resized = cv2.resize(image, (256, 256))\n",
                "    # Compute HOG descriptors\n",
                "    features, hog_image = hog(image_resized, orientations=9, pixels_per_cell=(8, 8),\n",
                "                              cells_per_block=(4, 4), block_norm=\"L2\", visualize=True)\n",
                "    return features, hog_image\n",
                "\n",
                "def apply_kmeans(image, n_clusters=4):\n",
                "    pixels = image.reshape(-1, 3)\n",
                "    kmeans = KMeans(n_clusters=n_clusters, n_init=\"auto\")\n",
                "    kmeans.fit(pixels)\n",
                "    \n",
                "    segmented_image = kmeans.cluster_centers_[kmeans.labels_]\n",
                "    segmented_image = segmented_image.reshape(image.shape).astype('uint8')\n",
                "\n",
                "    return segmented_image"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## VGG16 - VGGFace"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Import libraries\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install tensorflow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt \n",
                "import numpy as np \n",
                "import os \n",
                "import cv2\n",
                "import random\n",
                "import pickle\n",
                "import itertools\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential, load_model\n",
                "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.preprocessing import image\n",
                "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
                "from tensorflow.keras import optimizers\n",
                "from tensorflow.keras import utils\n",
                "from tensorflow.keras import layers\n",
                "from tensorflow.keras.utils import plot_model\n",
                "from tensorflow.keras.applications.vgg16 import VGG16\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from keras.utils import to_categorical \n",
                "%matplotlib inline\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Define Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_results(mod_history, metric, epochs):\n",
                "      \n",
                "      # Check out our train loss and test loss over epochs.\n",
                "      train_metric = mod_history.history[metric]\n",
                "      val = 'val_' + metric\n",
                "      test_metric = mod_history.history[val]\n",
                "\n",
                "      # Set figure size.\n",
                "      plt.figure(figsize=(12, 8))\n",
                "\n",
                "      # Generate line plot of training, testing loss over epochs.\n",
                "      plt.plot(train_metric, label=f'Training {metric}', color='#185fad')\n",
                "      plt.plot(test_metric, label=f'Testing {metric}', color='orange')\n",
                "\n",
                "      # Set title\n",
                "      plt.title(f'Training and Testing {metric} by Epoch', fontsize = 25)\n",
                "      plt.xlabel('Epoch', fontsize = 18)\n",
                "      plt.ylabel('Categorical Crossentropy', fontsize = 18)\n",
                "      plt.xticks(range(0,epochs,5), range(0,epochs,5))\n",
                "      plt.legend(fontsize = 18);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_predictions(mod_name, steps=20):\n",
                "    preds = mod_name.predict(X_test,steps=steps)\n",
                "    preds = preds.argmax(axis=-1)\n",
                "\n",
                "    y_test_labels = np.argmax(y_test, axis=-1)\n",
                "\n",
                "    cm = confusion_matrix(y_test_labels,preds)\n",
                "\n",
                "    plot_confusion_matrix(cm, cm_plot_labels, normalize=True,\n",
                "                          title='Face Shape Normalized')\n",
                "\n",
                "    plt.show()\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cm_plot_labels = ['Heart','Oblong','Oval','Round', 'Square']\n",
                "\n",
                "def plot_confusion_matrix(cm, classes,\n",
                "                          normalize=False,\n",
                "                          title='Confusion matrix',\n",
                "                          cmap=plt.cm.Blues):\n",
                "    \"\"\"\n",
                "    This function prints and plots the confusion matrix.\n",
                "    Normalization can be applied by setting `normalize=True`.\n",
                "    \"\"\"\n",
                "    if normalize:\n",
                "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
                "        print(\"Normalized confusion matrix\")\n",
                "    else:\n",
                "        print('Confusion matrix, without normalization')\n",
                "\n",
                "    print(cm)\n",
                "\n",
                "    plt.figure(figsize=(16,8))\n",
                "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
                "    plt.title(title)\n",
                "    plt.colorbar()\n",
                "    tick_marks = np.arange(len(classes))\n",
                "    plt.xticks(tick_marks, classes, rotation=45)\n",
                "    plt.yticks(tick_marks, classes)\n",
                "\n",
                "    fmt = '.2f' if normalize else 'd'\n",
                "    thresh = cm.max() / 2.\n",
                "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
                "        plt.text(j, i, format(cm[i, j], fmt),\n",
                "                 horizontalalignment=\"center\",\n",
                "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.ylabel('True label')\n",
                "    plt.xlabel('Predicted label')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_summary_results(mod_name, mod_history, epochs):\n",
                "    plot_results(mod_history, 'loss',epochs)\n",
                "    plot_results(mod_history, 'accuracy', epochs)\n",
                "    make_predictions(mod_name)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load Data Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def feature_engineering(path):\n",
                "    labels = []\n",
                "    images = []\n",
                "    shape_types = ['Heart', 'Oblong', 'Oval', 'Round', 'Square']\n",
                "\n",
                "    for shape in shape_types:\n",
                "        print(f'Loading {shape} images...')\n",
                "        shape_dir = os.path.join(path, shape)\n",
                "        if not os.path.exists(shape_dir):\n",
                "            print(f\"Directory {shape_dir} does not exist.\")\n",
                "            continue\n",
                "        for imgName in os.listdir(shape_dir):\n",
                "            img_path = os.path.join(shape_dir, imgName)\n",
                "            if not os.path.isfile(img_path):\n",
                "                print(f\"File {img_path} does not exist.\")\n",
                "                continue\n",
                "            img = cv2.imread(img_path)\n",
                "            if img is None:\n",
                "                print(f\"Image {img_path} could not be read.\")\n",
                "                continue\n",
                "            # Resize image to desired size (224, 224)\n",
                "            img = cv2.resize(img, (224, 224))\n",
                "            images.append(img)\n",
                "            labels.append(shape_types.index(shape))\n",
                "\n",
                "    labels = to_categorical(labels, num_classes=len(shape_types))\n",
                "    images = np.array(images)\n",
                "\n",
                "    return images, labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dir_train = \"/kaggle/input/face-shape-preprocessed/cropped_dataset/train\"\n",
                "dir_test = \"/kaggle/input/face-shape-preprocessed/cropped_dataset/test\"\n",
                "X_train, y_train = feature_engineering(dir_train)\n",
                "X_test, y_test = feature_engineering(dir_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Normalize pixel values to be between 0 and 1\n",
                "X_train = X_train / 255.0\n",
                "X_test = X_test / 255.0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Data Summary\")\n",
                "print(\"--------------------\")\n",
                "print(f\"X_train shape {X_train.shape}\")\n",
                "print(f\"y_train shape {y_train.shape}\")\n",
                "print(\"--------------------\")\n",
                "print(f\"X_test shape {X_test.shape}\")\n",
                "print(f\"y_test shape {y_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model TL: Transfer Learning from VGG16 with weights from VGG Face"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Path for VGGFace weights\n",
                "\n",
                "path_vggface = '/kaggle/input/vggface16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Loading VGG16 as base model\n",
                "base_model = VGG16(input_shape=(224, 224, 3),  # same as our input\n",
                "                   include_top=False,  # exclude the last layer\n",
                "                   weights=path_vggface)  # use VGGFace Weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for layer in base_model.layers:\n",
                "    layer.trainable = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_t1 = Sequential() # "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setting up the layer\n",
                "from tensorflow.keras import regularizers\n",
                "x = base_model.output\n",
                "#x = layers.GlobalAveragePooling2D()(x)\n",
                "\n",
                "x = layers.Flatten()(x)      # flatten the output of the Base Model\n",
                "\n",
                "# x = layers.Dense(512, activation='relu')(x)  # add 1 fully connected layer, try with 512 neurons first\n",
                "\n",
                "x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n",
                "x = layers.BatchNormalization()(x)\n",
                "x = layers.Dropout(0.5)(x)                   # add a dropout layer set 0.5 or 50% of the inputs unit to 0 at each update during training \n",
                "\n",
                "# x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n",
                "# x = layers.BatchNormalization()(x)\n",
                "# x = layers.Dropout(0.5)(x)                   # add a dropout layer set 0.5 or 50% of the inputs unit to 0 at each update during training \n",
                "\n",
                "x = layers.Dense(5, activation='softmax')(x)  # add final layer\n",
                "\n",
                "model_t1 = tf.keras.models.Model(base_model.input, x) # create the Model\n",
                "\n",
                "# Compile and Fit the model\n",
                "\n",
                "model_t1.compile(loss='categorical_crossentropy', # categorical_crossentropy loss used for multiclass classification \n",
                "                 optimizer='adam',\n",
                "                 metrics=['accuracy'])\n",
                "\n",
                "model_t1.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "datagen = ImageDataGenerator(rotation_range=20, horizontal_flip=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "datagen.fit(X_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# history_t1 = model_t1.fit(datagen.flow(X_train, y_train, batch_size=32), \n",
                "#                           steps_per_epoch=len(X_train)/32, epochs=80, \n",
                "#                           validation_data=(X_test, y_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
                "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
                "history_t1 = model_t1.fit(datagen.flow(X_train, y_train, batch_size=32), \n",
                "                          steps_per_epoch=len(X_train)/32, epochs=50, \n",
                "                          validation_data=(X_test, y_test),\n",
                "                          callbacks = [lr_scheduler])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_path = '/kaggle/working/saved_models/'\n",
                "tf.keras.models.save_model(\n",
                "    model_t1, filepath=model_path, overwrite=True, include_optimizer=True, save_format=None,\n",
                "    signatures=None, options=None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "filename = model_path + 'vgg16-face-1'   # change the filename for new iterations\n",
                "model_t1.save(filename)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "loaded_model = tf.keras.models.load_model(filename)\n",
                "mod_t1_predict = np.argmax(model_t1.predict(X_test), axis=1) \n",
                "loaded_t1_predict = np.argmax(loaded_model.predict(X_test), axis=1)\n",
                "\n",
                "# Check the difference\n",
                "\n",
                "print(f'Difference in predictions: Saved model vs. original model is {np.sum(loaded_t1_predict - mod_t1_predict)}\\nModel was correctly saved.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_summary_results(model_t1, history_t1, 50)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}